#!/novo/projects/ag_speciale/.venv/bin/python
"""
Diffusion Model for denoising latent representations
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from tqdm import tqdm


# ============= Noise Schedules =============
def linear_beta_schedule(timesteps, beta_start=1e-4, beta_end=0.02):
    return torch.linspace(beta_start, beta_end, timesteps)


def cosine_beta_schedule(timesteps, s=0.008):
    steps = timesteps + 1
    x = torch.linspace(0, timesteps, steps)
    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2
    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])
    return torch.clip(betas, 0.0001, 0.9999)


def sigmoidal_beta_schedule(timesteps, start=1e-5, end=1e-2):
    betas = torch.linspace(-6, 6, timesteps)
    betas = torch.sigmoid(betas) * (end - start) + start
    return torch.clip(betas, 0.0001, 0.9999)


# ============= Diffusion Process =============
class GaussianDiffusion:
    def __init__(self, timesteps=2000, beta_schedule='sigmoid', device='cpu'):
        self.timesteps = timesteps
        self.device = device
        
        if beta_schedule == 'linear':
            betas = linear_beta_schedule(timesteps)
        elif beta_schedule == 'cosine':
            betas = cosine_beta_schedule(timesteps)
        elif beta_schedule == 'sigmoid':
            betas = sigmoidal_beta_schedule(timesteps)
        
        self.betas = betas.to(device)
        self.alphas = (1. - self.betas).to(device)
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).to(device)
        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0).to(device)
        
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod).to(device)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod).to(device)
        self.posterior_variance = (self.betas * (1. - self.alphas_cumprod_prev) / (1. - self.alphas_cumprod)).to(device)
    
    def q_sample(self, x_start, t, noise=None):
        """Forward diffusion process"""
        if noise is None:
            noise = torch.randn_like(x_start)
        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t].reshape(-1, 1)
        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)
        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise
    
    def p_sample(self, model, x_t, t, device):
        """Reverse diffusion - single denoising step"""
        betas_t = self.betas[t].reshape(-1, 1)
        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1)
        sqrt_recip_alphas_t = torch.sqrt(1.0 / self.alphas[t]).reshape(-1, 1)
        
        predicted_noise = model(x_t, t)
        model_mean = sqrt_recip_alphas_t * (
            x_t - betas_t * predicted_noise / sqrt_one_minus_alphas_cumprod_t
        )
        
        if t[0] == 0:
            return model_mean
        else:
            posterior_variance_t = self.posterior_variance[t].reshape(-1, 1)
            noise = torch.randn_like(x_t)
            return model_mean + torch.sqrt(posterior_variance_t) * noise

    @torch.no_grad()
    def denoise(self, model, noisy_latents, device, denoise_steps=None, verbose=True):
        """
        Refine clean latent vectors x0 by:
            1) Adding noise at time t = denoise_steps
            2) Running reverse deffisuion from t ->0
        """
        if denoise_steps is None:
            denoise_steps = self.timesteps // 2
        
        b = noisy_latents.shape[0]
        x0 = noisy_latents
        
        # ------------------------------------------------------------
        # (1) Forward Noising
        # ------------------------------------------------------------
        t_forward = torch.full((b,), denoise_steps, device=device, dtype=torch.long)
        x = self.q_sample(x0, t_forward)


        # ------------------------------------------------------------
        # (2) Reverse Denoising
        # ------------------------------------------------------------
        iterator = tqdm(reversed(range(0, denoise_steps)), desc='Denoising', total=denoise_steps) if verbose else reversed(range(0, denoise_steps))
        
        for i in iterator:
            t = torch.full((b,), i, device=device, dtype=torch.long)
            x = self.p_sample(model, x, t, device)
        
        return x


# ============= Denoising Network =============
class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
    
    def forward(self, time):
        device = time.device
        half_dim = self.dim // 2
        embeddings = np.log(10000) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = time[:, None] * embeddings[None, :]
        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)
        return embeddings


class LatentDenoiser(nn.Module):
    """MLP-based denoiser for latent vectors"""
    def __init__(self, latent_dim, n_steps, hidden_dim=512, time_dim=256, num_layers=4,
                 position_embedding='sinusoidal'):
        super().__init__()
        self.latent_dim = latent_dim
        self.hidden_dim = hidden_dim
        self.position_embedding = position_embedding
        self.num_layers = num_layers
        
        if position_embedding == 'sinusoidal':
            self.time_mlp = nn.Sequential(
                SinusoidalPositionEmbeddings(time_dim),
                nn.Linear(time_dim, time_dim),
                nn.GELU(),
                nn.Linear(time_dim, time_dim),
            )
            
            layers = []
            layers.append(nn.Linear(latent_dim + time_dim, hidden_dim))
            layers.append(nn.GELU())
            
            for _ in range(num_layers - 2):
                layers.append(nn.Linear(hidden_dim, hidden_dim))
                layers.append(nn.GELU())
                layers.append(nn.LayerNorm(hidden_dim))
            
            layers.append(nn.Linear(hidden_dim, latent_dim))
            self.net = nn.Sequential(*layers)
            
        elif position_embedding == 'learned':
            self.step_embeddings = nn.ModuleList([
                nn.Embedding(n_steps, hidden_dim)
                for _ in range(num_layers - 1)
            ])
            
            self.linears = nn.ModuleList()
            self.linears.append(nn.Linear(latent_dim, hidden_dim))
            self.linears.append(nn.ReLU())
            
            for _ in range(num_layers - 2):
                self.linears.append(nn.Linear(hidden_dim, hidden_dim))
                self.linears.append(nn.ReLU())
            
            self.linears.append(nn.Linear(hidden_dim, latent_dim))
    
    def forward(self, x, t):
        if self.position_embedding == 'sinusoidal':
            t_emb = self.time_mlp(t)
            x = torch.cat([x, t_emb], dim=-1)
            return self.net(x)
        elif self.position_embedding == 'learned':
            for idx, embedding_layer in enumerate(self.step_embeddings):
                t_embedding = embedding_layer(t)
                x = self.linears[2 * idx](x)
                x = x + t_embedding
                x = self.linears[2 * idx + 1](x)
            x = self.linears[-1](x)
            return x

#!/novo/projects/ag_speciale/.venv/bin/python
"""
VAE Model for scRNA-seq data with ZINB distribution
"""
import torch
import torch.nn as nn
import torch.nn.functional as F


class scRNAVAE(nn.Module):
    def __init__(self, input_dim, latent_dim=20, hidden_dims=[128, 64], dropout_rate=0.1):
        super(scRNAVAE, self).__init__()
        self.input_dim = input_dim
        self.latent_dim = latent_dim
        
        # Encoder
        encoder_layers = []
        prev_dim = input_dim
        for hidden_dim in hidden_dims:
            encoder_layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        self.encoder = nn.Sequential(*encoder_layers)
        
        # Latent space
        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)
        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)
        
        # Decoder
        decoder_layers = []
        prev_dim = latent_dim
        for hidden_dim in reversed(hidden_dims):
            decoder_layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.BatchNorm1d(hidden_dim),
                nn.ReLU(),
                nn.Dropout(dropout_rate)
            ])
            prev_dim = hidden_dim
        self.decoder = nn.Sequential(*decoder_layers)
        
        # Output layers for ZINB parameters
        self.fc_mu_output = nn.Linear(hidden_dims[0], input_dim)
        self.fc_theta = nn.Linear(hidden_dims[0], input_dim)
        self.fc_pi = nn.Linear(hidden_dims[0], input_dim)
    
    def encode(self, x):
        h = self.encoder(x)
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.decoder(z)
        # Use softplus for positive parameters (more stable than exp)
        mu = F.softplus(self.fc_mu_output(h)) + 1e-4
        theta = F.softplus(self.fc_theta(h)) + 1e-4
        pi = torch.sigmoid(self.fc_pi(h))
        # Clamp to safe ranges
        pi = torch.clamp(pi, min=1e-4, max=1-1e-4)
        return mu, theta, pi 

    def forward(self, x):
        mu_z, logvar_z = self.encode(x)
        z = self.reparameterize(mu_z, logvar_z)
        mu_x, theta, pi = self.decode(z)
        return mu_x, theta, pi, mu_z, logvar_z
    
    def get_latent(self, x):
        """Get latent representation without reparameterization"""
        with torch.no_grad():
            mu, _ = self.encode(x)
        return mu


def zinb_loss(x, mu, theta, pi):
    """Zero-Inflated Negative Binomial loss"""
    eps = 1e-10
    t1 = torch.lgamma(theta + eps) + torch.lgamma(x + 1.0) - torch.lgamma(x + theta + eps)
    t2 = (theta + x) * torch.log(1.0 + (mu / (theta + eps))) + (x * (torch.log(theta + eps) - torch.log(mu + eps)))
    nb_case = t1 + t2 - torch.log(1.0 - pi + eps)
    
    zero_nb = torch.pow(theta / (theta + mu + eps), theta)
    zero_case = -torch.log(pi + ((1.0 - pi) * zero_nb) + eps)
    
    result = torch.where(x < 1e-8, zero_case, nb_case)
    return result.sum(dim=-1).mean()


def vae_loss(x, mu_x, theta, pi, mu_z, logvar_z, kl_weight=1.0):
    """Combined VAE loss: reconstruction + KL divergence"""
    recon_loss = zinb_loss(x, mu_x, theta, pi)
    kl_loss = -0.5 * torch.sum(1 + logvar_z - mu_z.pow(2) - logvar_z.exp(), dim=1).mean()
    return recon_loss + kl_weight * kl_loss, recon_loss, kl_loss